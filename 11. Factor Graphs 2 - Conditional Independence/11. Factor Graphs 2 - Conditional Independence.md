## Factor Graphs 2 - Conditional Independence

![](2024-05-10-15-40-24.png)

![](2024-05-10-15-42-30.png)
![](2024-05-10-15-43-40.png)
![](2024-05-10-15-46-26.png)
Gonna be really slow, exponential time
![](2024-05-10-15-48-19.png)
We have these things but they can only work for constraints
only when a factor that gives us a zero, then we know we can prune that branch
So if we have a factor that is non-zero, we can't use any of these...

So, backtracking is slow, but it gives u the optimal solution all the time

![](2024-05-10-15-53-46.png)
![](2024-05-10-15-59-17.png)
We have sensors that gives us noisy estimates for where is the thing every point at a time.
But the sensor is noisy, we cannot fully trust it, so we need to assign true locations 
![](2024-05-10-16-00-45.png)
Observation Factor: How close is our guess to the observation(what sensor said)

![](2024-05-10-16-07-41.png)

![](2024-05-10-16-11-58.png)
So now we run the backtrack algorithm, and it returns solution, where X1, X2, X3 are at position 1, 2, 2
![](2024-05-10-16-11-39.png)

![](2024-05-10-16-14-09.png)

# Beam Search

## Gready search
![](2024-05-10-16-14-54.png)
Backtrack gets us the best solution, but it is very slow, let's try to speed it up

![](2024-05-10-16-29-21.png)
One way to speed it up is Greedy search, where we only look at the branch that gives us higher weight  at this local window.

Pros: Very fast, linear
Cons: Very narrow window, you don't see a lot of state space, you don't explore so u will often miss the global max
![](2024-05-10-16-31-29.png)
So this basically says we loop and take the highest weight variable only

## Beam Search
Beam Search is kind of like in between of backtracking and greedy

Instead of maintianing only 1 partial like greedy, we maintian a list of K partial assignments
- We have k partial assignments
- Extend them with **all** possible succssors
- Sort them by their weight and Take only top K partial assignments
- And move on
![](2024-05-10-16-40-48.png)
![](2024-05-10-16-42-07.png)
![](2024-05-10-16-42-51.png)
Time complexity:
`b`: branching factor - domain, you need to try out every possible solutions
`K`: we are maintaining partial assignments of size K, for each K we try all values in domain. so it's K*b
`(K*b)log(K*b)`: we always need to sort all possible assignments and take top K, the sort takes NlogN
`n`: the depth of the tree - we have n variables

# Local search
![](2024-05-13-10-53-52.png)
We already have a complete assignment, and we are trying to make changes to it and improve it (improve the overral weight)

![](2024-05-13-11-00-25.png)

In this case we already have the assignment (0,0,1), and improve based on X2
so we try out all the values it can take on, which is 0, 1, 2
Then we recompute the weight and pick whatever value is the best.
In this example we found (0,1,1) is the best

![](2024-05-13-11-04-38.png)
One cool thing about ICM:
When evaluating a new value for that variable,
we only need to consider factors that touch that variable. 
Cuz everything else is consistant with respect to it, and it saves a lot of time.

Iterated conditional modes:
You can solve the whole CSP by this way
But it does not guarentee an optimal solution, it converges to local optimum
![](2024-05-13-11-08-33.png)
In this example it converges to 4, however backtrack gives us the optimum is 8
![](2024-05-13-11-10-56.png)

# Gibbs sampling
One way around this is a second algorithm called `Gibbs sampling`
With Gibbs sampling we are injecting some radomness into the process and try to bump us out of those local optima, into sth that can maybe get up a better area.
![](2024-05-13-11-15-01.png)
 
Gibbs sampling is super similar to ICM, we still try out all the values
The only difference is that, instead of selecting the value that gives u the heighest weight,
we sample the value, according with probability that's proportional to its weight
1/5 -> 0.2
2/5 -> 0.4
2/5 -> 0.4
![](2024-05-13-11-21-08.png)

## Example
![](2024-05-13-11-22-54.png)
We keep tracking a count of how many times we have this assignment
Overtime, we will find some high weights with some assignment is gonna occur very often

Thus the global optima is (usually) the most frequent, which is really cool

## What can go wrong?
![](2024-05-13-11-57-52.png)
If we have a problem, two ppl, going to restaurant(vege or steak house).
Constraints:
They wanna go to the same restaurant
They both really wanna eat vege.
They eat steaks but they are not super crazy about it

If somehow they follow the probability and choose (S,S)= 50
There's no way they can find the actual global optima is (V,V) = 100
Because changing one variable assignment resulting in (S, V) or (V, S), and it's much worse
It's really hard to bounce between (S,S) and (V,V)
In order to make it to (V,V) from (S,S), one has to make the decision to go to different restaurant, which  has a really low value

So a single Gibbs sampling is not guaranteed to find the global optima
![](2024-05-13-12-04-32.png)
Answer: Only backtracking
Greedy is too narrow
Beam search is `maybe` too narrow
ICM is too myopic (short-sighted)
Gibbs sampling is trying to find, it's likely but not a guarantee

![](2024-05-13-12-09-13.png)

![](2024-05-13-13-34-51.png)
# Conditioning
![](2024-05-13-13-32-36.png)

![](2024-05-13-14-02-18.png)
A and B are independent if there no factor/edges/paths that connects them

![](2024-05-13-14-03-39.png)

![](2024-05-13-14-04-29.png)
![](2024-05-13-14-05-07.png)
That's when we need to introduce this idea of conditioning
conditioning is a way to rip nodes out of a graph


Q: Will all CSP problems can be represented as graph problems?
A: Yes, variables are nodes and factors/constraints are edges

![](2024-05-13-14-07-49.png) 

![](2024-05-13-14-15-15.png)
So what if let's say X2 is definitely blue?
We reduced the binary factor into a unary fator(Since X2 doesn't matter now)
The price to pay is that (at the condition of X2 is being blue)
![](2024-05-13-14-23-27.png)
![](2024-05-13-14-20-25.png)
![](2024-05-13-14-21-47.png)

## Conditional independent
![](2024-05-13-14-24-24.png)
![](2024-05-13-14-26-25.png) 
We say A and B are conditionally independent, because once we condition on C(once we pick a value for C), 
A - C and B - C turns into stumps, and now there's no edges or path that connecting them or reach each other.

![](2024-05-13-14-27-33.png)
![](2024-05-13-14-28-10.png) 

## Markov blanket
Pick one or more variables
What are the variables that I have to destory to make my variable an island(independent)

Examples:
![](2024-05-13-14-51-26.png)
Pick: V
Markov blanket: SA NSW

The set of node you have to conditional on, is called the markov blanket of the set of nodes you want to be independent
The set notion:
![](2024-05-13-14-53-32.png)
![](2024-05-13-14-53-20.png)

## Example
So now we can use this idea to create independent structure now
So we can just repeatedly condition the value and solve
![](2024-05-13-14-56-50.png)
So this becomes very quick and you can read the maximum weight very easily

> This covers all the possible combinations that backtracking could have
> But this is much faster, cuz we are taking a very complicated problem and break down into easily solvable pieces

In this example we are traking an exponential problem and break it into a linear number of linear solvable problems
![](2024-05-13-15-10-54.png)
![](2024-05-13-15-04-44.png)
![](2024-05-13-15-06-11.png)

# Elimination

![](2024-07-26-15-42-10.png)
We dynamically choose the best value for x2

So now for any value of x1, the value of x2 is set, it's fixed
![](2024-07-26-15-42-47.png)
![](2024-07-26-15-43-28.png)
![](2024-07-26-15-45-10.png)
We can run elimination on the whole graph and the last variable will hold the best answer
![](2024-07-26-15-56-05.png)
![](2024-07-26-15-56-33.png)

![](2024-07-26-15-57-55.png)

![](2024-07-26-15-59-50.png)
You go forward and eliminate, then you go backward and read the choices

![](2024-07-26-16-03-59.png)
![](2024-07-26-16-04-54.png)
![](2024-07-26-16-05-26.png)
![](2024-07-26-16-09-43.png)
In general, the treewidth, it quite hard to compute 

![](2024-07-26-16-10-29.png) 